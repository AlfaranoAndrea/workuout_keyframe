{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3dbfd5-a260-4982-9952-c702ad8ccb25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fi/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/fi/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/fi/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/fi/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import os, os.path\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.nn.init import kaiming_normal_, constant_\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import flowiz\n",
    "from pytorch_lightning.strategies import DDPStrategy\n",
    "\n",
    "import flow_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128fc7c-c70c-4782-9427-58f91674b33c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b105355-7475-4356-aaf9-1c66c5f3048f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a539600-eb47-45c7-81ed-c5762d0fff63",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a594f65-57d6-4db1-a292-6c04f5ffdf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModuleFlyingChairs(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "          \n",
    "        # Directory to store FlyingChairs Data\n",
    "        self.download_dir = './root'     \n",
    "        # Defining batch size of our data\n",
    "        self.batch_size =  8 if torch.cuda.is_available() else 32\n",
    "          \n",
    "        # Defining transforms to be applied on the data\n",
    "        self.div_flow = 20 #Factor by which we divide the output (thus >=1). It makes training more stable to deal with low numbers than big ones.\n",
    "                      #Normalized for the Flying Chair Dataset (https://github.com/ClementPinard/FlowNetPytorch/issues/101#issuecomment-805222823)\n",
    "        \n",
    "        \n",
    "        self.input_transform = transforms.Compose([flow_transforms.ArrayToTensor(), \n",
    "                                      transforms.Normalize(mean=[0,0,0], std=[255,255,255]), \n",
    "                                      transforms.Normalize(mean=[0.45,0.432,0.411], std=[1,1,1])\n",
    "                                     ])\n",
    "\n",
    "        self.target_transform = transforms.Compose([flow_transforms.ArrayToTensor(),\n",
    "                                       transforms.Normalize(mean=[0,0],std=[self.div_flow,self.div_flow])])\n",
    "\n",
    "        self.co_transform = flow_transforms.Compose([flow_transforms.RandomCrop((320,448)), \n",
    "                                        flow_transforms.RandomVerticalFlip(),\n",
    "                                        flow_transforms.RandomHorizontalFlip()])\n",
    "        \n",
    "    def get_input_transform():\n",
    "        return  self.input_transform\n",
    "    \n",
    "    def get_target_transform():\n",
    "        return  self.target_transform \n",
    "    \n",
    "    def get_co_transform():\n",
    "        return  self.co_transform\n",
    "    \n",
    "    def train_transformation(self, input1, input2,flow,valid_flow_mask):\n",
    "        \n",
    "        valid_flow_mask= None\n",
    "        input1 = np.array(input1,dtype= np.float32)\n",
    "        input2 = np.array(input2,dtype= np.float32)\n",
    "        #print(f\"array start f1 shape {input1.shape}\")\n",
    "        \n",
    "        input1   = np.transpose (input1,(2,0,1))\n",
    "        input2   = np.transpose (input2,(2,0,1))\n",
    "        #print(f\"array  f1 shape {flow.shape}\")\n",
    "        #print(f\"array  n1 shape {input1.shape}\")\n",
    "        #print(f\"array  n2 shape {input2.shape}\")\n",
    "      #  inputs = [input1,input2]\n",
    "        \n",
    "        \n",
    "#         inputs, flow = self.co_transform(inputs, flow)\n",
    "\n",
    "      \n",
    "#         inputs[0] = self.input_transform(inputs[0])\n",
    "#         inputs[1] = self.input_transform(inputs[1])\n",
    "        \n",
    "#         flow = self.target_transform(flow)\n",
    "        \n",
    "   #     input1, input2 = inputs\n",
    "        return input1, input2 , flow, valid_flow_mask\n",
    "\n",
    "    def test_transformation(self, input1, input2,flow,valid_flow_mask):\n",
    "        \n",
    "        valid_flow_mask= None\n",
    "        input1= np.array(input1)\n",
    "        input2= np.array(input2)\n",
    "        flow   = np.transpose(flow)\n",
    "        inputs = [input1,input2]\n",
    "        \n",
    "                \n",
    "        crop=flow_transforms.CenterCrop((370,1224))\n",
    "        \n",
    "        inputs, flow = crop(inputs, flow)\n",
    "     \n",
    "        inputs[0] = self.input_transform(inputs[0])\n",
    "        inputs[1] = self.input_transform(inputs[1])\n",
    "        \n",
    "        flow = self.target_transform(flow)\n",
    "        \n",
    "        input1, input2 = inputs\n",
    "        return input1, input2 , flow ,valid_flow_mask\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "       \n",
    "  \n",
    "    def setup(self, stage=None):\n",
    "        \n",
    "          # Loading our data after applying the transforms\n",
    "        self.train_data = datasets.FlyingChairs(self.download_dir,\n",
    "                              split = \"train\", \n",
    "                              transforms = self.train_transformation)\n",
    "\n",
    "        self.test_data = datasets.FlyingChairs(self.download_dir,\n",
    "                                        split = \"val\",\n",
    "                                        transforms = self.test_transformation)\n",
    "  \n",
    "    def train_dataloader(self):\n",
    "        \n",
    "          # Generating train_dataloader\n",
    "        return DataLoader(self.train_data, \n",
    "                          batch_size = self.batch_size,\n",
    "                          num_workers = 8)\n",
    "  \n",
    "   \n",
    "  \n",
    "    def test_dataloader(self):\n",
    "        \n",
    "        # Generating test_dataloader\n",
    "        return DataLoader(self.test_data,\n",
    "                          batch_size = self.batch_size,\n",
    "                          num_workers = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ef9a6c-fd6a-4567-9bf9-76fd2087c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataModulo = DataModuleFlyingChairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1bdc535-3d97-4a29-8caf-ae8fc429ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= datasets.FlyingChairs('./root' ,\n",
    "                              split = \"train\", \n",
    "                              transforms = dataModulo.train_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d48f9cdc-6bbf-4be3-a812-100841a0c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #a3=a2[1].cpu().detach().numpy()\n",
    "# #a2[0].shape\n",
    "# #a3=np.transpose (a3,(1,2a,0))\n",
    "# print(type(a[1]))\n",
    "# plt.imshow(a[1][1])\n",
    "\n",
    "# type(a2[0][1][20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa35b67-9296-4d71-a73e-b329b9dc0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataModulo.setup()\n",
    "b=dataModulo.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5e882a-e1fc-48a2-8a8a-4dade5d6aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for b1, b2 in enumerate(b):\n",
    "   #print(b2[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80eb18d-7297-4473-8556-13b7f6c2bd09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model basic blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16906568-39e4-447e-9fd2-424fbfd67fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convBlock( in_channels, out_channels, kernel_size=3, stride=1, batchNormalization=False):\n",
    "    if(batchNormalization== True):\n",
    "        return nn.Sequential( nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                                        stride=stride,  padding=(kernel_size-1)//2, bias=False),\n",
    "                              nn.BatchNorm2d(out_channels),\n",
    "                              nn.LeakyReLU(negative_slope=0.1,inplace=True)\n",
    "                            )\n",
    "    else:\n",
    "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                                        stride=stride,  padding=(kernel_size-1)//2, bias=True),\n",
    "                              nn.LeakyReLU(negative_slope=0.1,inplace=True)\n",
    "                            )\n",
    "    \n",
    "def predict_block(in_channels):\n",
    "    return nn.Conv2d(in_channels, 2, kernel_size=3, stride=1, padding =1, bias=False)\n",
    "\n",
    "def deconvolution_block(in_channels, out_channels):\n",
    "    return nn.Sequential ( nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                          nn.LeakyReLU(negative_slope=0.1,inplace=True)\n",
    "                        )\n",
    "\n",
    "#Define a Cropping Operation\n",
    "def crop_like(input, target):\n",
    "    if input.size()[2:] == target.size()[2:]:\n",
    "        return input\n",
    "    else:\n",
    "        return input[:, :, :target.size(2), :target.size(3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec77167f-3f5e-46b9-8167-a92759b915de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0993a65d-768e-476c-a77d-567d3a40bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowNetS(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    " \n",
    "        #ENCODER PART\n",
    "        #self.batchNorm = batchNorm\n",
    "        self.conv1   = convBlock(6,   64, kernel_size=7, stride=2, batchNormalization=True)\n",
    "        self.conv2   = convBlock(64,  128, kernel_size=5, stride=2, batchNormalization=True)\n",
    "        self.conv3   = convBlock(128,  256, kernel_size=5, stride=2, batchNormalization=True)\n",
    "        self.conv3_1 = convBlock(256,  256, batchNormalization=True)\n",
    "        self.conv4   = convBlock(256,  512, stride=2, batchNormalization=True)\n",
    "        self.conv4_1 = convBlock(512,  512, batchNormalization=True)\n",
    "        self.conv5   = convBlock( 512,  512, stride=2, batchNormalization=True)\n",
    "        self.conv5_1 = convBlock(512,  512, batchNormalization=True)\n",
    "        self.conv6   = convBlock(512, 1024, stride=2, batchNormalization=True)\n",
    "        self.conv6_1 = convBlock(1024, 1024, batchNormalization=True) # Note: This one doesn't exist in the paper, but it does in their implementation\n",
    "\n",
    "        #REFINEMENT PART\n",
    "        self.deconv5 = deconvolution_block(1024,512)\n",
    "        self.deconv4 = deconvolution_block(1026,256)\n",
    "        self.deconv3 = deconvolution_block(770,128)\n",
    "        self.deconv2 = deconvolution_block(386,64)\n",
    "\n",
    "        self.predict_flow6 = predict_block(1024)\n",
    "        self.predict_flow5 = predict_block(1026)\n",
    "        self.predict_flow4 = predict_block(770)\n",
    "        self.predict_flow3 = predict_block(386)\n",
    "        self.predict_flow2 = predict_block(194)\n",
    "\n",
    "        self.upsampled_flow6_to_5 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n",
    "        self.upsampled_flow5_to_4 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n",
    "        self.upsampled_flow4_to_3 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n",
    "        self.upsampled_flow3_to_2 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n",
    "\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                # Initialize the Convolutions with \"He Initialization\" to 0.1 (https://arxiv.org/pdf/1502.01852.pdf)\n",
    "                kaiming_normal_(m.weight, 0.1)\n",
    "                if m.bias is not None:\n",
    "                    # Initialize all bias to 0\n",
    "                    constant_(m.bias, 0)\n",
    "            # Initialize the BatchNorm Convolutions with \"He Initialization\" to 1 (https://arxiv.org/pdf/1502.01852.pdf)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                constant_(m.weight, 1)\n",
    "                constant_(m.bias, 0)\n",
    "                \n",
    "    def forward (self, x):\n",
    "        # ENCODER\n",
    "        out_conv2 = self.conv2(self.conv1(x))\n",
    "        out_conv3 = self.conv3_1(self.conv3(out_conv2))\n",
    "        out_conv4 = self.conv4_1(self.conv4(out_conv3))\n",
    "        out_conv5 = self.conv5_1(self.conv5(out_conv4))\n",
    "        out_conv6 = self.conv6_1(self.conv6(out_conv5))\n",
    "        \n",
    "        # REFINEMENT\n",
    "        flow6       = self.predict_flow6(out_conv6)\n",
    "        flow6_up    = crop_like(self.upsampled_flow6_to_5(flow6), out_conv5)\n",
    "        out_deconv5 = crop_like(self.deconv5(out_conv6), out_conv5)\n",
    "\n",
    "        concat5 = torch.cat((out_conv5,out_deconv5,flow6_up),1)\n",
    "        flow5       = self.predict_flow5(concat5)\n",
    "        flow5_up    = crop_like(self.upsampled_flow5_to_4(flow5), out_conv4)\n",
    "        out_deconv4 = crop_like(self.deconv4(concat5), out_conv4)\n",
    "\n",
    "        concat4 = torch.cat((out_conv4,out_deconv4,flow5_up),1)\n",
    "        flow4       = self.predict_flow4(concat4)\n",
    "        flow4_up    = crop_like(self.upsampled_flow4_to_3(flow4), out_conv3)\n",
    "        out_deconv3 = crop_like(self.deconv3(concat4), out_conv3)\n",
    "\n",
    "        concat3 = torch.cat((out_conv3,out_deconv3,flow4_up),1)\n",
    "        flow3       = self.predict_flow3(concat3)\n",
    "        flow3_up    = crop_like(self.upsampled_flow3_to_2(flow3), out_conv2)\n",
    "        out_deconv2 = crop_like(self.deconv2(concat3), out_conv2)\n",
    "\n",
    "        concat2 = torch.cat((out_conv2,out_deconv2,flow3_up),1)\n",
    "        flow2 = self.predict_flow2(concat2)\n",
    "\n",
    "        if self.training:\n",
    "            return flow2,flow3,flow4,flow5,flow6\n",
    "        else:\n",
    "            return flow2\n",
    "        \n",
    "    def weight_parameters(self):\n",
    "        return [param for name, param in self.named_parameters() if 'weight' in name]\n",
    "\n",
    "    def bias_parameters(self):\n",
    "        return [param for name, param in self.named_parameters() if 'bias' in name]\n",
    "      \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # --------------------------\n",
    "        # REPLACE WITH YOUR OWN\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        flow2_EPEs = AverageMeter()\n",
    "        multiscale_weights = [0.005,0.01,0.02,0.08,0.32] # from output_flow to flow6\n",
    "        \n",
    "        #print (f\"batch len {len(batch)}\")\n",
    "        #print (f\"batch first element shape {batch[0].shape}\")\n",
    "        #print (f\"batch second element shape {batch[1].shape}\")\n",
    "        #print (f\"batch tird element shape {batch[2].shape}\")\n",
    "        x,x1, y = batch\n",
    "        x_train = torch.cat([x,x1],1)\n",
    "        #print (f\"x concat  shape {x_train.shape}\")\n",
    "        #print (f\"x concat type{type(x_train)}\")\n",
    "        output=self(x_train)\n",
    "        h, w = y.size()[-2:]\n",
    "        output = [F.interpolate(output[0], (h,w)), *output[1:]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print (f\"x_hat type{type(output)}\")\n",
    "        #print (f\"x_hat len  {len(output)}\")\n",
    "        #print (f\"x_hat[0] shape type{output[0].shape}\")\n",
    "        loss = multiscaleEPE(output, y, weights=multiscale_weights, sparse=True)\n",
    "\n",
    "        # Compute the Output EPE\n",
    "        flow2_EPE = 20 * realEPE(output[0], y, sparse=True)  #div_flow\n",
    "\n",
    "        # Record loss and EPE\n",
    "        losses.update(loss.item(), y.size(0))\n",
    "        #train_writer.add_scalar('train_loss', loss.item(), n_iter)\n",
    "        flow2_EPEs.update(flow2_EPE.item(), y.size(0))\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "        # --------------------------\n",
    "\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "     # --------------------------list all  numbers from 1 to 100 python\n",
    "        # REPLACE WITH YOUR OWN\n",
    "  \n",
    "        x, y = batch\n",
    "        x_hat = self(x)\n",
    "    \n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "        # --------------------------\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=10e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9f41b-d729-433b-b7bf-3f5d26e27300",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0064e4f1-52b6-4b1b-83cf-a658e164bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EPE(input_flow, target_flow, sparse=False, mean=True):\n",
    "    EPE_map = torch.norm(target_flow-input_flow,2,1)\n",
    "    batch_size = EPE_map.size(0)\n",
    "    if sparse:\n",
    "        # invalid flow is defined with both flow coordinates to be exactly 0\n",
    "        mask = (target_flow[:,0] == 0) & (target_flow[:,1] == 0)\n",
    "        EPE_map = EPE_map[~mask]\n",
    "    if mean:\n",
    "        return EPE_map.mean()\n",
    "    else:\n",
    "        return EPE_map.sum()/batch_size\n",
    "    \n",
    "def realEPE(output, target, sparse=False):\n",
    "    b, _, h, w = target.size()\n",
    "    upsampled_output = F.interpolate(output, (h,w), mode='bilinear', align_corners=False) # used to resize the output\n",
    "    return EPE(upsampled_output, target, sparse, mean=True)\n",
    "\n",
    "\n",
    "\n",
    "def sparse_max_pool(input, size):\n",
    "    '''Downsample the input by considering 0 values as invalid.\n",
    "    Unfortunately, no generic interpolation mode can resize a sparse map correctly,\n",
    "    the strategy here is to use max pooling for positive values and \"min pooling\"\n",
    "    for negative values, the two results are then summed.\n",
    "    This technique allows sparsity to be minized, contrary to nearest interpolation,\n",
    "    which could potentially lose information for isolated data points.'''\n",
    "\n",
    "    positive = (input > 0).float()\n",
    "    negative = (input < 0).float()\n",
    "    output = F.adaptive_max_pool2d(input * positive, size) - F.adaptive_max_pool2d(-input * negative, size)\n",
    "    return output\n",
    "\n",
    "\n",
    "def multiscaleEPE(network_output, target_flow, weights=None, sparse=False):\n",
    "    def one_scale(output, target, sparse):\n",
    "\n",
    "        b, _, h, w = output.size()\n",
    "        if sparse:\n",
    "            target_scaled = sparse_max_pool(target, (h, w))\n",
    "        else:\n",
    "            target_scaled = F.interpolate(target, (h, w), mode='area')\n",
    "        return EPE(output, target_scaled, sparse, mean=False)\n",
    "    \n",
    "\n",
    "    if type(network_output) not in [tuple, list]:\n",
    "        network_output = [network_output]\n",
    "    if weights is None:\n",
    "        weights = [0.005, 0.01, 0.02, 0.08, 0.32]  # as in original article\n",
    "    assert(len(weights) == len(network_output))\n",
    "\n",
    "    loss = 0\n",
    "    for output, weight in zip(network_output, weights):\n",
    "        loss += weight * one_scale(output, target_flow, sparse)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{:.3f} ({:.3f})'.format(self.val, self.avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc3116-66c4-4d9a-9f74-e761a3c3f76b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286e646b-1d45-4415-9c13-71f204493492",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataModuleFlyingChairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mDataModuleFlyingChairs\u001b[49m()\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m FlowNetS()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataModuleFlyingChairs' is not defined"
     ]
    }
   ],
   "source": [
    "data=DataModuleFlyingChairs()\n",
    "model = FlowNetS()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "     ddp= DDPStrategy(find_unused_parameters=False)\n",
    "     trainer = pl.Trainer(gpus=2, max_epochs=3, progress_bar_refresh_rate=20,strategy= ddp)\n",
    "     trainer.fit(model,data)\n",
    "\n",
    "# trainer = pl.Trainer(gpus=1, max_epochs=4, progress_bar_refresh_rate=20)\n",
    "# trainer.fit(model,data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
