{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d66e59f9-6c30-4c74-b345-322d88720910",
      "metadata": {
        "id": "d66e59f9-6c30-4c74-b345-322d88720910"
      },
      "source": [
        "## introduction\n",
        "### problem statement\n",
        "Every day always more people experience the opportunity of training overywhere: outdoor on a park, in a garage, in our bedroom etc. Anyway this possibility of freedom led to a great issue commont to every uncommon athlets: the lack of feedbacks.\n",
        "infact, while in a gym is easy receive a examination on own exercise esecution, by a trainer or by another athlet, on own bedroom we don't have this possibility. lack of feedback on exercise esecution led to learn improper esecutin, bring to weak performances, injuries etc\n",
        "\n",
        "### state of art \n",
        "to evaluete own proper execution, athlets sometimes use to record their performarce in order to self esaminate them and find what is wrong. Anyway this process is tedios becouse it involve the need to find a good place to put the smartphone,record the clip, skip all the preparation of exercise, find the most significative point on the esecution, examinate them and finaly understaining whats wrong for correcting mistakes on the next repetition.\n",
        "Do this proces for every rep, for every exercise, in time with rest time (usualy in the order of 1 minute), can be annoing and most athlets preferes to not be distracted and keep attention on their work out.\n",
        "\n",
        "### proposed solution \n",
        "my idea is to make all this process agile for the atlets, developing a computer vision pipeline that is able  to take the recordered clip, extrapolate the most important keyframe for the athlets, discard all the unnecessary moment to be keep user attention on the most important moment and give to final user a edited clipp to fast evaluate own performances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step O colab initialization"
      ],
      "metadata": {
        "id": "3dQNttFOb_0t"
      },
      "id": "3dQNttFOb_0t"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AlfaranoAndrea/workuout_keyframe.git\n",
        "%cd workuout_keyframe \n",
        "!gdown https://drive.google.com/drive/folders/148Mhwpt9E89_gLMAJC4S45DiVv83Xz54?usp=share_link --folder -O input_video\n"
      ],
      "metadata": {
        "id": "k_soW8umcKc2",
        "outputId": "d1be7a6d-f0a3-4c47-9fcd-c70255f9eed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k_soW8umcKc2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'workuout_keyframe'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 134 (delta 51), reused 98 (delta 38), pack-reused 4\u001b[K\n",
            "Receiving objects: 100% (134/134), 5.68 MiB | 9.96 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "/content/workuout_keyframe\n",
            "Retrieving folder list\n",
            "Processing file 1KC4dLg3R-RVVxKlEeXwidfX6CMcALzEX military.mp4\n",
            "Processing file 1VMJWvQ_dWtwkw6uaQUAV8s8zrFE1n6u6 poor_execution.mp4\n",
            "Processing file 1DILeSomSV_LVZK6O_LSDVQ7yhz52KDE_ pullup.mp4\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KC4dLg3R-RVVxKlEeXwidfX6CMcALzEX\n",
            "To: /content/workuout_keyframe/input_video/military.mp4\n",
            "100% 58.5M/58.5M [00:03<00:00, 16.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VMJWvQ_dWtwkw6uaQUAV8s8zrFE1n6u6\n",
            "To: /content/workuout_keyframe/input_video/poor_execution.mp4\n",
            "100% 48.9M/48.9M [00:02<00:00, 17.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DILeSomSV_LVZK6O_LSDVQ7yhz52KDE_\n",
            "To: /content/workuout_keyframe/input_video/pullup.mp4\n",
            "100% 44.8M/44.8M [00:02<00:00, 19.5MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /models/checkpoint/\n",
        "!wget \"drive.google.com/u/3/uc?id=1iAKv2S1OE3YpwgwX43bKZHxBAlluL9Y9&export=download&confirm=yes\" -O /models/checkpoint/flownets.pth.tar.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiDJX1CQ8l5v",
        "outputId": "1ff4637a-42f2-42db-96e6-991d26848204"
      },
      "id": "HiDJX1CQ8l5v",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-16 16:22:51--  http://drive.google.com/u/3/uc?id=1iAKv2S1OE3YpwgwX43bKZHxBAlluL9Y9&export=download&confirm=yes\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.2.100, 142.251.2.101, 142.251.2.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.2.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://drive.google.com/u/3/uc?id=1iAKv2S1OE3YpwgwX43bKZHxBAlluL9Y9&export=download&confirm=yes [following]\n",
            "--2023-02-16 16:22:51--  https://drive.google.com/u/3/uc?id=1iAKv2S1OE3YpwgwX43bKZHxBAlluL9Y9&export=download&confirm=yes\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.2.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.google.com/uc?id=1iAKv2S1OE3YpwgwX43bKZHxBAlluL9Y9&export=download&confirm=yes [following]\n",
            "--2023-02-16 16:22:51--  https://drive.google.com/uc?id=1iAKv2S1OE3YpwgwX43bKZHxBAlluL9Y9&export=download&confirm=yes\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-44-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/lcdecsop8tljb82jtoggq039hg5coikv/1676564550000/06430227796893093141/*/1iAKv2S1OE3YpwgwX43bKZHxBAlluL9Y9?e=download&uuid=e6b093a3-9bde-45f9-9c9b-991d4c4694ca [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-02-16 16:22:51--  https://doc-08-44-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/lcdecsop8tljb82jtoggq039hg5coikv/1676564550000/06430227796893093141/*/1iAKv2S1OE3YpwgwX43bKZHxBAlluL9Y9?e=download&uuid=e6b093a3-9bde-45f9-9c9b-991d4c4694ca\n",
            "Resolving doc-08-44-docs.googleusercontent.com (doc-08-44-docs.googleusercontent.com)... 142.250.141.132, 2607:f8b0:4023:c0b::84\n",
            "Connecting to doc-08-44-docs.googleusercontent.com (doc-08-44-docs.googleusercontent.com)|142.250.141.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154706010 (148M) [application/octet-stream]\n",
            "Saving to: ‘/models/checkpoint/flownets.pth.tar.pth’\n",
            "\n",
            "/models/checkpoint/ 100%[===================>] 147.54M  65.9MB/s    in 2.2s    \n",
            "\n",
            "2023-02-16 16:22:54 (65.9 MB/s) - ‘/models/checkpoint/flownets.pth.tar.pth’ saved [154706010/154706010]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 downloadSintel.py"
      ],
      "metadata": {
        "id": "dH_pjylmwcXl",
        "outputId": "3a07377c-4880-45b0-d15a-31c7f9afb5ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dH_pjylmwcXl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############### DOWNLOADING SINTEL DATA ###############\n",
            "5.50MKB [04:48, 19.0kKB/s]               \n",
            "############### UNZIPPING SINTEL DATA ###############\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd5XiXj1EOs1",
        "outputId": "7bff9022-1b02-4cb2-eee9-40d19ab67dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pytorch_lightning --quiet\n",
        "!pip install flowiz --quiet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.7/2.1 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for eel (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "id": "dd5XiXj1EOs1"
    },
    {
      "cell_type": "markdown",
      "id": "1465ddb8-00f0-493c-8a8e-568f16ea2c98",
      "metadata": {
        "id": "1465ddb8-00f0-493c-8a8e-568f16ea2c98",
        "tags": []
      },
      "source": [
        "# First part: Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6e3dbfd5-a260-4982-9952-c702ad8ccb25",
      "metadata": {
        "id": "6e3dbfd5-a260-4982-9952-c702ad8ccb25",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "9bcf3366-d8c9-4f2e-da54-e1d1cc276ac2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9b67032d1b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mflowiz\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mFlowDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flowiz'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import flowiz as fz\n",
        "\n",
        "from dataset import  FlowDataModule\n",
        "from models.flowNetS import FlowNetS\n",
        "from models.raft import RAFT\n",
        "\n",
        "from utilities.videoUtilities import extract_frames, saveVideo\n",
        "from utilities.flowUtilities import computeFlow, flowVideo\n",
        "from utilities.keyFramesUtilities import find_center_of_gravity, save_key_frames\n",
        "from utilities.signalUtilities import  movingAverage, findKeyPoints, normalizeZeroMean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a539600-eb47-45c7-81ed-c5762d0fff63",
      "metadata": {
        "id": "6a539600-eb47-45c7-81ed-c5762d0fff63",
        "tags": []
      },
      "source": [
        "# datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6b954c-367d-434c-9706-4039d875226f",
      "metadata": {
        "id": "2b6b954c-367d-434c-9706-4039d875226f",
        "tags": []
      },
      "source": [
        "let's visualize how torch vison dataset FlyingChairs works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1bdc535-3d97-4a29-8caf-ae8fc429ad11",
      "metadata": {
        "id": "f1bdc535-3d97-4a29-8caf-ae8fc429ad11"
      },
      "outputs": [],
      "source": [
        "loadedDataset= datasets.Sintel(root='./dataset',\n",
        "                              split = \"train\", \n",
        "                              #transforms = dataModulo.dataset_transformation,\n",
        "                              pass_name = \"clean\"\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48f9cdc-6bbf-4be3-a812-100841a0c525",
      "metadata": {
        "id": "d48f9cdc-6bbf-4be3-a812-100841a0c525"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "dataset gives back triplets [image1,image2, targetFlow]\n",
        "\"\"\"\n",
        "\n",
        "triplet=loadedDataset[10]\n",
        "img1,img2,flow= triplet\n",
        "\n",
        "img1=np.asarray(img1)\n",
        "img2=np.asarray(img2)\n",
        "\n",
        "print (f\"image1 in dataset has shape: {img1.shape}\")\n",
        "print (f\"image2 in dataset has shape: {img2.shape}\")\n",
        "\n",
        "print (f\"flow image in dataset has shape: {flow.shape}\")\n",
        "flow=np.transpose (flow,(1,2,0))\n",
        "print (f\"flow image in dataset has this new shape: {flow.shape}\")\n",
        "\n",
        "flow=fz.convert_from_flow(flow) \n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(img1)\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(img2)\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(flow)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9bc3116-66c4-4d9a-9f74-e761a3c3f76b",
      "metadata": {
        "id": "b9bc3116-66c4-4d9a-9f74-e761a3c3f76b",
        "tags": []
      },
      "source": [
        "## model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1def3d31",
      "metadata": {
        "id": "1def3d31"
      },
      "outputs": [],
      "source": [
        "save = torch.load(\"./models/checkpoint/flownets.pth.tar.pth\")#[\"state_dict\"]\n",
        "model  = FlowNetS(save)\n",
        "data=FlowDataModule(batch_size =1, workers=32,selected_dataset =\"Sintel\")\n",
        "\n",
        "trainer = pl.Trainer(accelerator= \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
        "                     max_epochs=20,             \n",
        "                     auto_lr_find=False, \n",
        "                     auto_scale_batch_size=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286e646b-1d45-4415-9c13-71f204493492",
      "metadata": {
        "id": "286e646b-1d45-4415-9c13-71f204493492",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer.fit(model,data )\n",
        "trainer.test(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c08cfaa-b20c-413f-a21a-63a90677d4ea",
      "metadata": {
        "id": "0c08cfaa-b20c-413f-a21a-63a90677d4ea",
        "tags": []
      },
      "source": [
        "# Second part: Computing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7e327b9-4c5d-49b8-8a2b-b793228e73ff",
      "metadata": {
        "id": "a7e327b9-4c5d-49b8-8a2b-b793228e73ff"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "save = torch.load(\"./models/checkpoint/flownets.pth.tar.pth\")#[\"state_dict\"]\n",
        "model  = FlowNetS(save)\n",
        "model.to(device)\n",
        "video_path= \"./input_video/pullup.mp4\"\n",
        "temp_extracted_frames=\"./temp/Frames/\"\n",
        "temp_processed_flow_frames=\"./temp/processedFloFrames/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "162671a2-491b-4b26-9221-d553d5da29fd",
      "metadata": {
        "id": "162671a2-491b-4b26-9221-d553d5da29fd"
      },
      "outputs": [],
      "source": [
        "fps=30\n",
        "step=6\n",
        "#fps=int(extract_frames(video_path))\n",
        "flowVideo(\n",
        "    path=temp_extracted_frames,\n",
        "    model=model,\n",
        "    device=device,\n",
        "    step=step)\n",
        "saveVideo(temp_processed_flow_frames,\"pippo\", fps=fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6367ca-dda8-42cb-aed5-8bc8a5120e9f",
      "metadata": {
        "id": "5c6367ca-dda8-42cb-aed5-8bc8a5120e9f"
      },
      "outputs": [],
      "source": [
        "# 3B- Find miving cordinates of center of gravity of our athlet\n",
        "x,y=find_center_of_gravity(temp_processed_flow_frames)  \n",
        "#saveVideo(comp,\"PullUp_mass\",bw=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6472254d-b7d5-4a78-bc1e-c75b6ad92e87",
      "metadata": {
        "id": "6472254d-b7d5-4a78-bc1e-c75b6ad92e87"
      },
      "source": [
        "## SIGNAL ANALISYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a607520d-2806-47fc-bb62-237c39a1842e",
      "metadata": {
        "id": "a607520d-2806-47fc-bb62-237c39a1842e"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "915e20cf-e4c3-459b-9a5e-fba88920d9b0",
      "metadata": {
        "id": "915e20cf-e4c3-459b-9a5e-fba88920d9b0"
      },
      "outputs": [],
      "source": [
        "# 2- mobile average\n",
        "#K=[0.25,0.25,0.25,0.25]\n",
        "\n",
        "\n",
        "#avg=np.convolve(K,y)\n",
        "avg= movingAverage(y,k=int(fps/step))\n",
        "normalized= normalizeZeroMean(avg)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(avg)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd4fe39-3cbf-4c3c-a8fc-749302e28c24",
      "metadata": {
        "id": "6fd4fe39-3cbf-4c3c-a8fc-749302e28c24"
      },
      "outputs": [],
      "source": [
        "# 3- find peacks positive\n",
        "peaks= findKeyPoints(normalized, distance=int(fps/step))\n",
        "\n",
        "\n",
        "np.diff(peaks)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(normalized)\n",
        "plt.plot(peaks, normalized[peaks], \"x\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1492199-30ab-4c4f-a967-fc071c9c4732",
      "metadata": {
        "id": "c1492199-30ab-4c4f-a967-fc071c9c4732"
      },
      "outputs": [],
      "source": [
        "save_key_frames(\n",
        "    keyFramesList=peaks, \n",
        "    frames_path=temp_extracted_frames,\n",
        "    threshold=12, \n",
        "    near=5, \n",
        "    slowmotion=2, \n",
        "    speedUp=4, \n",
        "    title=\"final.avi\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}